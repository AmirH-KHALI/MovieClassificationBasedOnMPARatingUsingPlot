{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13ZeDLxyaRtA"
      },
      "source": [
        "# **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9lgF3io8iDt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "527cefac-1652-43a6-f789-f25628edf251"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.9 MB 4.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 4.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 237 kB 10.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 37.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 56.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 12.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 92 kB 10.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 56.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 48.3 MB 74 kB/s \n",
            "\u001b[K     |████████████████████████████████| 99 kB 6.8 MB/s \n",
            "\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.3.2-py3-none-any.whl (362 kB)\n",
            "\u001b[K     |████████████████████████████████| 362 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 13.0 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 76.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 55.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 69.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 71.4 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 74.7 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 76.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, responses, huggingface-hub, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.3.2 frozenlist-1.3.0 fsspec-2022.5.0 huggingface-hub-0.8.1 multidict-6.0.2 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 52.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.5.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "Successfully installed tokenizers-0.12.1 transformers-4.20.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting autokeras\n",
            "  Downloading autokeras-1.0.19-py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from autokeras) (1.3.5)\n",
            "Collecting keras-tuner>=1.1.0\n",
            "  Downloading keras_tuner-1.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 51.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from autokeras) (21.3)\n",
            "Requirement already satisfied: tensorflow>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from autokeras) (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (5.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (1.21.6)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (2.8.0)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (2.23.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (14.0.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.46.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (3.1.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (2.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.14.1)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (0.26.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.1.2)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (3.17.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (57.4.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (0.5.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (2.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (4.1.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->autokeras) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.8.0->autokeras) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner>=1.1.0->autokeras) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner>=1.1.0->autokeras) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner>=1.1.0->autokeras) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner>=1.1.0->autokeras) (3.2.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (5.1.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.7.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner>=1.1.0->autokeras) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->autokeras) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->autokeras) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->autokeras) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner>=1.1.0->autokeras) (0.7.0)\n",
            "Installing collected packages: kt-legacy, keras-tuner, autokeras\n",
            "Successfully installed autokeras-1.0.19 keras-tuner-1.1.2 kt-legacy-1.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U \"tensorflow-text==2.8.*\"\n",
        "!pip install -q tf-models-official==2.7.0\n",
        "!pip install datasets\n",
        "!pip install transformers datasets\n",
        "!pip install autokeras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rw9F-DVOEEn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from tqdm import tqdm\n",
        "import string\n",
        "import os.path\n",
        "import matplotlib.pyplot as plt\n",
        "import ast\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from collections import Counter\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "import autokeras as ak\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1YKcYKajQhK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6b848a1-a2ce-4f64-d674-18c3da94f6fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive, auth\n",
        "# Mount Google Drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZY7b1jNj1Zs"
      },
      "outputs": [],
      "source": [
        "base_dir = './drive/MyDrive/University/00012-NLP/MovieClassification/'\n",
        "# base_dir = './'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YlqRoF5kQKW"
      },
      "source": [
        "# **Data Collection (Phase 1, Part 1)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myKJEMU-G0lc"
      },
      "outputs": [],
      "source": [
        "raw_list = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dbk-iAeOGhe"
      },
      "outputs": [],
      "source": [
        "def crawl(mpa):\n",
        "    for current_page in tqdm(range(1, 9952, 50)):\n",
        "        response = requests.get('https://www.imdb.com/search/title/?' \n",
        "                                + 'title_type=feature,tv_movie,tv_special,documentary,short,tv_short' \n",
        "                                + '&certificates=US%3A' + mpa \n",
        "                                + '&start=' + str(current_page))\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        for i in range(len(soup.select('h3.lister-item-header a'))):\n",
        "            title = soup.select('h3.lister-item-header a')[i].get_text()\n",
        "            plot = soup.select('p.text-muted')[2 * i + 1].get_text()\n",
        "            raw_list.append([title, mpa, plot])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qsLAbUAPGEs",
        "outputId": "230492b6-2e6f-4821-b2f2-7fcdb953e23e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [03:25<00:00,  1.03s/it]\n"
          ]
        }
      ],
      "source": [
        "crawl('G')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZpzWLAoJjM1",
        "outputId": "f834c43a-ca17-4d87-cada-fbbb319c875d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [05:37<00:00,  1.69s/it]\n"
          ]
        }
      ],
      "source": [
        "crawl('PG')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ffp8RpIfJkmT",
        "outputId": "6e9eb7aa-11e1-49cc-9f1f-086fcdf9eec1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:42<00:00,  1.41s/it]\n"
          ]
        }
      ],
      "source": [
        "crawl('PG-13')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_CMmjItJmZ7",
        "outputId": "a42457ca-87ab-497b-a985-a31260beb098"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [04:41<00:00,  1.41s/it]\n"
          ]
        }
      ],
      "source": [
        "crawl('R')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M-czyS9bQRhH",
        "outputId": "710d3f5a-61c8-4cb5-e089-7b90bc725beb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-79f1830e-f7ef-4912-9c63-53238136b696\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>MPA</th>\n",
              "      <th>Plot</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Toy Story</td>\n",
              "      <td>G</td>\n",
              "      <td>A cowboy doll is profoundly threatened and jea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cars</td>\n",
              "      <td>G</td>\n",
              "      <td>A hot-shot race-car named Lightning McQueen ge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Lion King</td>\n",
              "      <td>G</td>\n",
              "      <td>Lion prince Simba and his father are targeted ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Toy Story 4</td>\n",
              "      <td>G</td>\n",
              "      <td>When a new toy called \"Forky\" joins Woody and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Sound of Music</td>\n",
              "      <td>G</td>\n",
              "      <td>A young novitiate is sent by her convent in 19...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79f1830e-f7ef-4912-9c63-53238136b696')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-79f1830e-f7ef-4912-9c63-53238136b696 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-79f1830e-f7ef-4912-9c63-53238136b696');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                Title MPA                                               Plot\n",
              "0           Toy Story   G  A cowboy doll is profoundly threatened and jea...\n",
              "1                Cars   G  A hot-shot race-car named Lightning McQueen ge...\n",
              "2       The Lion King   G  Lion prince Simba and his father are targeted ...\n",
              "3         Toy Story 4   G  When a new toy called \"Forky\" joins Woody and ...\n",
              "4  The Sound of Music   G  A young novitiate is sent by her convent in 19..."
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_data = pd.DataFrame(raw_list, columns = ['Title', 'MPA', 'Plot'])\n",
        "raw_data.Plot = raw_data.Plot.apply(lambda p: p.replace('\\n', ''))\n",
        "raw_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NgWpAMEJVuE8"
      },
      "outputs": [],
      "source": [
        "if not os.path.isdir(base_dir + 'data/'):\n",
        "    os.mkdir(base_dir + 'data/')\n",
        "\n",
        "if not os.path.isdir(base_dir + 'data/raw/'):\n",
        "    os.mkdir(base_dir + 'data/raw/')\n",
        "\n",
        "raw_data.to_csv(base_dir + 'data/raw/data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9Xc011Hg52h"
      },
      "source": [
        "# **Preprocessing (Phase 1, Part 2)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "fXusQOqqhrw1",
        "outputId": "20efc243-606d-410a-ff59-d2f647cd2b61"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-33909ed0-be04-475c-b2d3-4ea308d066a2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>MPA</th>\n",
              "      <th>Plot</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>G</td>\n",
              "      <td>The Lion King</td>\n",
              "      <td>Lion prince Simba and his father are targeted ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>G</td>\n",
              "      <td>Cars</td>\n",
              "      <td>A hot-shot race-car named Lightning McQueen ge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>G</td>\n",
              "      <td>Ratatouille</td>\n",
              "      <td>A rat who can cook makes an unusual alliance w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>G</td>\n",
              "      <td>2001: A Space Odyssey</td>\n",
              "      <td>The Monoliths push humanity to reach for the s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>G</td>\n",
              "      <td>The Princess Diaries</td>\n",
              "      <td>Mia Thermopolis has just found out that she is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21595</th>\n",
              "      <td>R</td>\n",
              "      <td>Den of Thieves</td>\n",
              "      <td>An elite unit of the LA County Sheriff's Dept....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21596</th>\n",
              "      <td>R</td>\n",
              "      <td>Blade Runner 2049</td>\n",
              "      <td>Young Blade Runner K's discovery of a long-bur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21597</th>\n",
              "      <td>R</td>\n",
              "      <td>All the Old Knives</td>\n",
              "      <td>Two CIA agents and ex-lovers (Chris Pine and T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21598</th>\n",
              "      <td>R</td>\n",
              "      <td>Forgetting Sarah Marshall</td>\n",
              "      <td>Devastated Peter takes a Hawaiian vacation in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21599</th>\n",
              "      <td>R</td>\n",
              "      <td>The Power of the Dog</td>\n",
              "      <td>Charismatic rancher Phil Burbank inspires fear...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21600 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33909ed0-be04-475c-b2d3-4ea308d066a2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-33909ed0-be04-475c-b2d3-4ea308d066a2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-33909ed0-be04-475c-b2d3-4ea308d066a2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Title                        MPA  \\\n",
              "0         G              The Lion King   \n",
              "1         G                       Cars   \n",
              "2         G                Ratatouille   \n",
              "3         G      2001: A Space Odyssey   \n",
              "4         G       The Princess Diaries   \n",
              "...     ...                        ...   \n",
              "21595     R             Den of Thieves   \n",
              "21596     R          Blade Runner 2049   \n",
              "21597     R         All the Old Knives   \n",
              "21598     R  Forgetting Sarah Marshall   \n",
              "21599     R       The Power of the Dog   \n",
              "\n",
              "                                                    Plot  \n",
              "0      Lion prince Simba and his father are targeted ...  \n",
              "1      A hot-shot race-car named Lightning McQueen ge...  \n",
              "2      A rat who can cook makes an unusual alliance w...  \n",
              "3      The Monoliths push humanity to reach for the s...  \n",
              "4      Mia Thermopolis has just found out that she is...  \n",
              "...                                                  ...  \n",
              "21595  An elite unit of the LA County Sheriff's Dept....  \n",
              "21596  Young Blade Runner K's discovery of a long-bur...  \n",
              "21597  Two CIA agents and ex-lovers (Chris Pine and T...  \n",
              "21598  Devastated Peter takes a Hawaiian vacation in ...  \n",
              "21599  Charismatic rancher Phil Burbank inspires fear...  \n",
              "\n",
              "[21600 rows x 3 columns]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(base_dir + 'data/raw/data.csv', index_col=0)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDlmsVh0jHnT",
        "outputId": "67893c1d-5d4f-496b-f292-bf4028696607"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1LFWMovn17J"
      },
      "outputs": [],
      "source": [
        "df = df.drop(df[df.Plot == 'Add a Plot'].index)\n",
        "df = df.reset_index().drop(columns = 'index')\n",
        "df['Plot'] = df['Plot'].str.replace('See full summary', '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbWpg6_NiPY3"
      },
      "outputs": [],
      "source": [
        "df['Normalized_Plot'] = df['Plot'].str.lower()\n",
        "df['Normalized_Plot'] = df['Normalized_Plot'].str.translate(str.maketrans('', '', string.punctuation + '»' + '«'))\n",
        "df['Normalized_Plot'] = df['Normalized_Plot'].str.translate(str.maketrans('', '', string.digits))\n",
        "df['Normalized_Plot'] = df['Normalized_Plot'].apply(word_tokenize)\n",
        "df['Normalized_Plot'] = df['Normalized_Plot'].apply(lambda lst : [word for word in lst if word not in set(stopwords.words('english'))])\n",
        "df['Normalized_Plot'] = df['Normalized_Plot'].apply(lambda lst : [WordNetLemmatizer().lemmatize(w) for w in lst])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbe8XCDkNm3_"
      },
      "outputs": [],
      "source": [
        "if not os.path.isdir(base_dir + 'data/'):\n",
        "    os.mkdir(base_dir + 'data/')\n",
        "\n",
        "if not os.path.isdir(base_dir + 'data/cleaned/'):\n",
        "    os.mkdir(base_dir + 'data/cleaned/')\n",
        "\n",
        "df.to_csv(base_dir + 'data/cleaned/data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5dr_VuO5VGi"
      },
      "source": [
        "# **Statistics (Phase 1, Part 3)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "lOS6bT655Zv2",
        "outputId": "9f3964ac-5ce2-4a73-82d8-70ddda2cc285"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-86647fde-eb3b-4693-808d-3fe53157f100\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>MPA</th>\n",
              "      <th>Plot</th>\n",
              "      <th>Normalized_Plot</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Lion King</td>\n",
              "      <td>G</td>\n",
              "      <td>Lion prince Simba and his father are targeted ...</td>\n",
              "      <td>['lion', 'prince', 'simba', 'father', 'targete...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cars</td>\n",
              "      <td>G</td>\n",
              "      <td>A hot-shot race-car named Lightning McQueen ge...</td>\n",
              "      <td>['hotshot', 'racecar', 'named', 'lightning', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Luck</td>\n",
              "      <td>G</td>\n",
              "      <td>The curtain is pulled back on the millennia-ol...</td>\n",
              "      <td>['curtain', 'pulled', 'back', 'millenniaold', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001: A Space Odyssey</td>\n",
              "      <td>G</td>\n",
              "      <td>The Monoliths push humanity to reach for the s...</td>\n",
              "      <td>['monolith', 'push', 'humanity', 'reach', 'sta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ratatouille</td>\n",
              "      <td>G</td>\n",
              "      <td>A rat who can cook makes an unusual alliance w...</td>\n",
              "      <td>['rat', 'cook', 'make', 'unusual', 'alliance',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27396</th>\n",
              "      <td>Zombie Diaries</td>\n",
              "      <td>R</td>\n",
              "      <td>An unknown virus begins spreading and within w...</td>\n",
              "      <td>['unknown', 'virus', 'begin', 'spreading', 'wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27397</th>\n",
              "      <td>Gangsta Rap: The Glockumentary</td>\n",
              "      <td>R</td>\n",
              "      <td>The hardest group you've never heard of is bac...</td>\n",
              "      <td>['hardest', 'group', 'youve', 'never', 'heard'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27398</th>\n",
              "      <td>Satan's Sadists</td>\n",
              "      <td>R</td>\n",
              "      <td>The \"Satans\" are a very cruel biker gang led b...</td>\n",
              "      <td>['satan', 'cruel', 'biker', 'gang', 'led', 'an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27399</th>\n",
              "      <td>Train of Life</td>\n",
              "      <td>R</td>\n",
              "      <td>In 1941, the inhabitants of a small Jewish vil...</td>\n",
              "      <td>['inhabitant', 'small', 'jewish', 'village', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27400</th>\n",
              "      <td>The Devil's Female</td>\n",
              "      <td>R</td>\n",
              "      <td>After the gruesome death of her father, a youn...</td>\n",
              "      <td>['gruesome', 'death', 'father', 'young', 'beau...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27401 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86647fde-eb3b-4693-808d-3fe53157f100')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-86647fde-eb3b-4693-808d-3fe53157f100 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-86647fde-eb3b-4693-808d-3fe53157f100');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                Title MPA  \\\n",
              "0                       The Lion King   G   \n",
              "1                                Cars   G   \n",
              "2                                Luck   G   \n",
              "3               2001: A Space Odyssey   G   \n",
              "4                         Ratatouille   G   \n",
              "...                               ...  ..   \n",
              "27396                  Zombie Diaries   R   \n",
              "27397  Gangsta Rap: The Glockumentary   R   \n",
              "27398                 Satan's Sadists   R   \n",
              "27399                   Train of Life   R   \n",
              "27400              The Devil's Female   R   \n",
              "\n",
              "                                                    Plot  \\\n",
              "0      Lion prince Simba and his father are targeted ...   \n",
              "1      A hot-shot race-car named Lightning McQueen ge...   \n",
              "2      The curtain is pulled back on the millennia-ol...   \n",
              "3      The Monoliths push humanity to reach for the s...   \n",
              "4      A rat who can cook makes an unusual alliance w...   \n",
              "...                                                  ...   \n",
              "27396  An unknown virus begins spreading and within w...   \n",
              "27397  The hardest group you've never heard of is bac...   \n",
              "27398  The \"Satans\" are a very cruel biker gang led b...   \n",
              "27399  In 1941, the inhabitants of a small Jewish vil...   \n",
              "27400  After the gruesome death of her father, a youn...   \n",
              "\n",
              "                                         Normalized_Plot  \n",
              "0      ['lion', 'prince', 'simba', 'father', 'targete...  \n",
              "1      ['hotshot', 'racecar', 'named', 'lightning', '...  \n",
              "2      ['curtain', 'pulled', 'back', 'millenniaold', ...  \n",
              "3      ['monolith', 'push', 'humanity', 'reach', 'sta...  \n",
              "4      ['rat', 'cook', 'make', 'unusual', 'alliance',...  \n",
              "...                                                  ...  \n",
              "27396  ['unknown', 'virus', 'begin', 'spreading', 'wi...  \n",
              "27397  ['hardest', 'group', 'youve', 'never', 'heard'...  \n",
              "27398  ['satan', 'cruel', 'biker', 'gang', 'led', 'an...  \n",
              "27399  ['inhabitant', 'small', 'jewish', 'village', '...  \n",
              "27400  ['gruesome', 'death', 'father', 'young', 'beau...  \n",
              "\n",
              "[27401 rows x 4 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(base_dir + 'data/cleaned/data.csv', index_col=0)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ju0rVFEBxb-1",
        "outputId": "0a165eb9-aa65-4069-bcc5-9457c6c6c565"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "MPA_counts = {MPA : sum(df['MPA'] == MPA) for MPA in ['G', 'PG', 'PG-13', 'R']}\n",
        "plt.bar(MPA_counts.keys(), MPA_counts.values())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "19_7kJz6pLJQ",
        "outputId": "a2338aa5-4902-4468-d861-9e5532fd1ac2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "counter = Counter()\n",
        "df['Normalized_Plot'].apply(lambda lst : ast.literal_eval(lst)).apply(counter.update)\n",
        "\n",
        "counter_list = [(k, v) for k, v in sorted(counter.items(), key=lambda item: item[1], reverse=True)]\n",
        "counter_list = counter_list[:10]\n",
        "x, y = zip(*counter_list)\n",
        "plt.figure(figsize=(10, 5), facecolor=None)\n",
        "plt.bar(x, y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6av-dHaNMM2Q",
        "outputId": "2fe11cc7-f389-4a5a-b986-ee5ca12e8429"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence count: 39317\n",
            "All words(preprocessed words): 422248\n",
            "Unique words: 34538\n"
          ]
        }
      ],
      "source": [
        "print('Sentence count:', df['Plot'].apply(sent_tokenize).apply(len).sum())\n",
        "print('All words(preprocessed words):', sum(counter.values()))\n",
        "print('Unique words:', len(counter))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYhASMaCA_4s"
      },
      "source": [
        "# **Train Preprocessing (Phase 2)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQvklixbBFvh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "724c7af7-3678-4db0-c52e-a8432f89ab78"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                Title MPA  \\\n",
              "0                       The Lion King   G   \n",
              "1                                Cars   G   \n",
              "2                                Luck   G   \n",
              "3               2001: A Space Odyssey   G   \n",
              "4                         Ratatouille   G   \n",
              "...                               ...  ..   \n",
              "27396                  Zombie Diaries   R   \n",
              "27397  Gangsta Rap: The Glockumentary   R   \n",
              "27398                 Satan's Sadists   R   \n",
              "27399                   Train of Life   R   \n",
              "27400              The Devil's Female   R   \n",
              "\n",
              "                                                    Plot  \\\n",
              "0      Lion prince Simba and his father are targeted ...   \n",
              "1      A hot-shot race-car named Lightning McQueen ge...   \n",
              "2      The curtain is pulled back on the millennia-ol...   \n",
              "3      The Monoliths push humanity to reach for the s...   \n",
              "4      A rat who can cook makes an unusual alliance w...   \n",
              "...                                                  ...   \n",
              "27396  An unknown virus begins spreading and within w...   \n",
              "27397  The hardest group you've never heard of is bac...   \n",
              "27398  The \"Satans\" are a very cruel biker gang led b...   \n",
              "27399  In 1941, the inhabitants of a small Jewish vil...   \n",
              "27400  After the gruesome death of her father, a youn...   \n",
              "\n",
              "                                         Normalized_Plot  \n",
              "0      [lion, prince, simba, father, targeted, bitter...  \n",
              "1      [hotshot, racecar, named, lightning, mcqueen, ...  \n",
              "2      [curtain, pulled, back, millenniaold, battle, ...  \n",
              "3      [monolith, push, humanity, reach, star, discov...  \n",
              "4      [rat, cook, make, unusual, alliance, young, ki...  \n",
              "...                                                  ...  \n",
              "27396  [unknown, virus, begin, spreading, within, wee...  \n",
              "27397  [hardest, group, youve, never, heard, back, se...  \n",
              "27398  [satan, cruel, biker, gang, led, anchor, gang,...  \n",
              "27399  [inhabitant, small, jewish, village, central, ...  \n",
              "27400  [gruesome, death, father, young, beautiful, wo...  \n",
              "\n",
              "[27401 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cdfd1fc5-4b4a-44b3-8f9b-e0ff65f9bf7d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>MPA</th>\n",
              "      <th>Plot</th>\n",
              "      <th>Normalized_Plot</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Lion King</td>\n",
              "      <td>G</td>\n",
              "      <td>Lion prince Simba and his father are targeted ...</td>\n",
              "      <td>[lion, prince, simba, father, targeted, bitter...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cars</td>\n",
              "      <td>G</td>\n",
              "      <td>A hot-shot race-car named Lightning McQueen ge...</td>\n",
              "      <td>[hotshot, racecar, named, lightning, mcqueen, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Luck</td>\n",
              "      <td>G</td>\n",
              "      <td>The curtain is pulled back on the millennia-ol...</td>\n",
              "      <td>[curtain, pulled, back, millenniaold, battle, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001: A Space Odyssey</td>\n",
              "      <td>G</td>\n",
              "      <td>The Monoliths push humanity to reach for the s...</td>\n",
              "      <td>[monolith, push, humanity, reach, star, discov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ratatouille</td>\n",
              "      <td>G</td>\n",
              "      <td>A rat who can cook makes an unusual alliance w...</td>\n",
              "      <td>[rat, cook, make, unusual, alliance, young, ki...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27396</th>\n",
              "      <td>Zombie Diaries</td>\n",
              "      <td>R</td>\n",
              "      <td>An unknown virus begins spreading and within w...</td>\n",
              "      <td>[unknown, virus, begin, spreading, within, wee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27397</th>\n",
              "      <td>Gangsta Rap: The Glockumentary</td>\n",
              "      <td>R</td>\n",
              "      <td>The hardest group you've never heard of is bac...</td>\n",
              "      <td>[hardest, group, youve, never, heard, back, se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27398</th>\n",
              "      <td>Satan's Sadists</td>\n",
              "      <td>R</td>\n",
              "      <td>The \"Satans\" are a very cruel biker gang led b...</td>\n",
              "      <td>[satan, cruel, biker, gang, led, anchor, gang,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27399</th>\n",
              "      <td>Train of Life</td>\n",
              "      <td>R</td>\n",
              "      <td>In 1941, the inhabitants of a small Jewish vil...</td>\n",
              "      <td>[inhabitant, small, jewish, village, central, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27400</th>\n",
              "      <td>The Devil's Female</td>\n",
              "      <td>R</td>\n",
              "      <td>After the gruesome death of her father, a youn...</td>\n",
              "      <td>[gruesome, death, father, young, beautiful, wo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27401 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdfd1fc5-4b4a-44b3-8f9b-e0ff65f9bf7d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cdfd1fc5-4b4a-44b3-8f9b-e0ff65f9bf7d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cdfd1fc5-4b4a-44b3-8f9b-e0ff65f9bf7d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df = pd.read_csv(base_dir + 'data/cleaned/data.csv', index_col=0)\n",
        "df['Normalized_Plot'] = df['Normalized_Plot'].apply(lambda lst : ast.literal_eval(lst))\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSoHmGqTFBId"
      },
      "outputs": [],
      "source": [
        "mpa_dict = {'G': 0, 'PG': 1, 'PG-13': 2, 'R': 3}\n",
        "df['label'] = [mpa_dict[x] for x in df['MPA']]\n",
        "df['text'] = [' '.join(x) for x in df['Normalized_Plot']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxjCurB6Ztw6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37d5d370-9a2a-4410-b2e2-d9d8e33e51bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((20550,), (20550, 4), (6851,), (6851, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df['text'], df['label'])\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes=4)\n",
        "y_test = to_categorical(y_test, num_classes=4)\n",
        "\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Simple Text Classification Model (Phase 2, Part 2)**"
      ],
      "metadata": {
        "id": "XUfudrIy3O9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 20000\n",
        "embedding_dim = 128\n",
        "sequence_length = 500"
      ],
      "metadata": {
        "id": "kJjhPnTf3a_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer = TextVectorization(\n",
        "    max_tokens=max_features,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "vectorize_layer.adapt(x_train)"
      ],
      "metadata": {
        "id": "y3lnYHut4DQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_input = tf.keras.Input(shape=(1,), dtype=tf.string, name='text')\n",
        "x = vectorize_layer(text_input)\n",
        "x = layers.Embedding(max_features + 1, embedding_dim)(x)\n",
        "\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "# Conv1D + global max pooling\n",
        "x = layers.Conv1D(128, 7, padding='valid', activation='relu', strides=3)(x)\n",
        "x = layers.Conv1D(128, 7, padding='valid', activation='relu', strides=3)(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "\n",
        "# We add a vanilla hidden layer:\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
        "predictions = layers.Dense(4, activation='sigmoid', name='predictions')(x)\n",
        "\n",
        "model = tf.keras.Model(text_input, predictions)\n",
        "\n",
        "# Compile the model with binary crossentropy loss and an adam optimizer.\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "nk5QWOyZ4Ekj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(tf.constant(x_train), y_train, validation_split=0.2, epochs=3)"
      ],
      "metadata": {
        "id": "HnSZHk0l4UGR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "553ae0dc-3857-4ba6-814b-bf5487ddcda0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "514/514 [==============================] - 6s 10ms/step - loss: 1.2706 - accuracy: 0.3876 - val_loss: 1.1760 - val_accuracy: 0.4577\n",
            "Epoch 2/3\n",
            "514/514 [==============================] - 5s 10ms/step - loss: 1.0769 - accuracy: 0.5018 - val_loss: 1.1964 - val_accuracy: 0.4421\n",
            "Epoch 3/3\n",
            "514/514 [==============================] - 5s 9ms/step - loss: 0.8191 - accuracy: 0.6464 - val_loss: 1.3834 - val_accuracy: 0.4219\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f90fe023210>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(base_dir + 'models/simple_text_classification', save_format = \"tf\")\n",
        "loaded_model = load_model(base_dir + 'models/simple_text_classification')\n",
        "loaded_model.evaluate(tf.constant(x_test), y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_RppDVgEhW2",
        "outputId": "64c44f0b-8fac-41da-a606-2ebb1e9c8650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/University/00012-NLP/MovieClassification/models/simple_text_classification/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/University/00012-NLP/MovieClassification/models/simple_text_classification/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "215/215 [==============================] - 1s 6ms/step - loss: 1.3922 - accuracy: 0.4261\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.392188310623169, 0.4260692000389099]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Improved Text Classification Models (Phase 2, Part 3)**"
      ],
      "metadata": {
        "id": "OcAi136WKw_A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Text Classification Using Transformers layer**"
      ],
      "metadata": {
        "id": "IutsBQuJ3cja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 20000\n",
        "embedding_dim = 128\n",
        "sequence_length = 500\n",
        "\n",
        "num_heads = 2  # Number of attention heads\n",
        "ff_dim = 32  # Hidden layer size in feed forward network inside transformer"
      ],
      "metadata": {
        "id": "FMYkD0sr4je6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = tf.keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "metadata": {
        "id": "64pgMVnQ3jcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ],
      "metadata": {
        "id": "9sIhwK0l4en1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_input = tf.keras.Input(shape=(1,), dtype=tf.string, name='text')\n",
        "x = vectorize_layer(text_input)\n",
        "\n",
        "embedding_layer = TokenAndPositionEmbedding(sequence_length, max_features, embedding_dim)\n",
        "x = embedding_layer(x)\n",
        "\n",
        "transformer_block = TransformerBlock(embedding_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x)\n",
        "\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "\n",
        "x = layers.Dense(20, activation='relu')(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "\n",
        "outputs = layers.Dense(4, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=text_input, outputs=outputs)"
      ],
      "metadata": {
        "id": "veuLEqEH4f6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=3, validation_split=0.2)"
      ],
      "metadata": {
        "id": "Fw542DwG4o5F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a53ea1f8-e5c7-4472-82b0-2248829e9c79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "514/514 [==============================] - 21s 35ms/step - loss: 1.3396 - accuracy: 0.3584 - val_loss: 1.3073 - val_accuracy: 0.3745\n",
            "Epoch 2/3\n",
            "514/514 [==============================] - 17s 33ms/step - loss: 1.2198 - accuracy: 0.4210 - val_loss: 1.1750 - val_accuracy: 0.4545\n",
            "Epoch 3/3\n",
            "514/514 [==============================] - 17s 33ms/step - loss: 1.0471 - accuracy: 0.5191 - val_loss: 1.2111 - val_accuracy: 0.4509\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8e4b6e2050>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(base_dir + 'models/text_classification_using_transformers', save_format = \"tf\")\n",
        "loaded_model = load_model(base_dir + 'models/text_classification_using_transformers')\n",
        "loaded_model.evaluate(tf.constant(x_test), y_test)"
      ],
      "metadata": {
        "id": "XX5tJxZZ4xus",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "834804d8-b752-4fb5-c4e0-bfa66dc2e810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_3_layer_call_fn, embedding_3_layer_call_and_return_conditional_losses, embedding_4_layer_call_fn, embedding_4_layer_call_and_return_conditional_losses, multi_head_attention_1_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/University/00012-NLP/MovieClassification/models/text_classification_using_transformers/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/University/00012-NLP/MovieClassification/models/text_classification_using_transformers/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "215/215 [==============================] - 3s 13ms/step - loss: 1.2192 - accuracy: 0.4396\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2192487716674805, 0.43964385986328125]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Text Classification Using Bert**"
      ],
      "metadata": {
        "id": "YqxQs2kT3j0D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvvJyRKue_bw",
        "outputId": "635318a9-6462-4db5-bc1c-5d0cd8d0ead1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1\n",
            "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
          ]
        }
      ],
      "source": [
        "bert_model_name = 'small_bert/bert_en_uncased_L-10_H-512_A-8'\n",
        "\n",
        "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1'\n",
        "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
        "\n",
        "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
        "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpUXofhtfHfx"
      },
      "outputs": [],
      "source": [
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8GxJEIugO66",
        "outputId": "495c44e5-2f2e-42bd-d510-2e16dd5e47c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hi bitchez!']\n",
            "Keys       : ['input_word_ids', 'input_type_ids', 'input_mask']\n",
            "Shape      : (1, 128)\n",
            "Word Ids   : [ 101 7632 7743 9351  999  102    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0]\n",
            "Input Mask : [1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "text_test = ['Hi bitchez!']\n",
        "text_preprocessed = bert_preprocess_model(text_test)\n",
        "\n",
        "print(text_test)\n",
        "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
        "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
        "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, : 20]}')\n",
        "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, : 20]}')\n",
        "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, : 20]}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
      ],
      "metadata": {
        "id": "4vM6cMgnhKOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_results = bert_model(text_preprocessed)\n",
        "\n",
        "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
        "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
        "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
        "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
        "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9hU7GmchLUp",
        "outputId": "c0f1c966-f611-420d-cceb-4920f840ef06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1\n",
            "Pooled Outputs Shape:(1, 512)\n",
            "Pooled Outputs Values:[ 0.33562768 -0.2538585   0.5599888   0.76626843  0.5676474  -0.60505533\n",
            " -0.32637784 -0.9982774   0.2438279   0.9987538  -0.5719133  -0.97347873]\n",
            "Sequence Outputs Shape:(1, 128, 512)\n",
            "Sequence Outputs Values:[[ 0.31094003  0.15382561  1.0201985  ... -0.57107294 -1.365524\n",
            "   0.05360165]\n",
            " [ 0.1665078  -0.37277767 -0.2602708  ...  0.0699846  -1.1501445\n",
            "  -0.2759685 ]\n",
            " [-0.34534103 -0.03975188 -0.9905317  ... -0.21089089 -0.39083523\n",
            "   0.64529866]\n",
            " ...\n",
            " [-0.36674708 -0.22294529 -0.02585383 ...  0.08165319 -0.47791135\n",
            "  -0.05833472]\n",
            " [-0.19746575  0.19652915 -0.5719107  ...  0.07476798 -0.18116426\n",
            "   0.829659  ]\n",
            " [ 0.6483316   0.0970015   0.64028853 ... -0.11531498 -0.59721863\n",
            "  -0.0704602 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_classifier_model():\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "    encoder_inputs = preprocessing_layer(text_input)\n",
        "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "    outputs = encoder(encoder_inputs)\n",
        "    net = outputs['pooled_output']\n",
        "    net = tf.keras.layers.Dense(4, activation='softmax', name='classifier')(net)\n",
        "    return tf.keras.Model(text_input, net)"
      ],
      "metadata": {
        "id": "5f5HYFQOhYGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model = build_classifier_model()\n",
        "bert_raw_result = classifier_model(tf.constant(text_test))\n",
        "print(tf.sigmoid(bert_raw_result))\n",
        "classifier_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_c33Clx0hcC-",
        "outputId": "41d981de-83cb-484b-e98b-6f908143d0dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0.5097018 0.5128283 0.6508063 0.5713298]], shape=(1, 4), dtype=float32)\n",
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " preprocessing (KerasLayer)     {'input_mask': (Non  0           ['text[0][0]']                   \n",
            "                                e, 128),                                                          \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128)}                                                      \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'default': (None,   47677953    ['preprocessing[0][0]',          \n",
            "                                512),                             'preprocessing[0][1]',          \n",
            "                                 'sequence_output':               'preprocessing[0][2]']          \n",
            "                                 (None, 128, 512),                                                \n",
            "                                 'encoder_outputs':                                               \n",
            "                                 [(None, 128, 512),                                               \n",
            "                                 (None, 128, 512),                                                \n",
            "                                 (None, 128, 512),                                                \n",
            "                                 (None, 128, 512),                                                \n",
            "                                 (None, 128, 512),                                                \n",
            "                                 (None, 128, 512),                                                \n",
            "                                 (None, 128, 512),                                                \n",
            "                                 (None, 128, 512),                                                \n",
            "                                 (None, 128, 512),                                                \n",
            "                                 (None, 128, 512)],                                               \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 512)}                                                       \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 4)            2052        ['BERT_encoder[0][11]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 47,680,005\n",
            "Trainable params: 47,680,004\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "QLrsIZjJhxjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model.fit(x_train, y_train, validation_split=.3, epochs=3, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U1qLvlQmo27",
        "outputId": "a544b5e3-78b9-489d-e28a-e7444bd526fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "225/225 [==============================] - 244s 1s/step - loss: 1.3752 - accuracy: 0.3383 - val_loss: 1.3305 - val_accuracy: 0.3631\n",
            "Epoch 2/3\n",
            "225/225 [==============================] - 230s 1s/step - loss: 1.3362 - accuracy: 0.3491 - val_loss: 1.3383 - val_accuracy: 0.3631\n",
            "Epoch 3/3\n",
            "225/225 [==============================] - 230s 1s/step - loss: 1.3393 - accuracy: 0.3466 - val_loss: 1.3344 - val_accuracy: 0.3631\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4fefb162d0>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model.save(base_dir + 'models/text_classification_using_bert', save_format = \"tf\")\n",
        "loaded_model = load_model(base_dir + 'models/text_classification_using_bert')\n",
        "loaded_model.evaluate(tf.constant(x_test), y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TbBNc5oHZaN",
        "outputId": "ce223a29-08d7-4778-e5f3-94ffcbe30994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 124). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/University/00012-NLP/MovieClassification/models/text_classification_using_bert/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/University/00012-NLP/MovieClassification/models/text_classification_using_bert/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "215/215 [==============================] - 23s 104ms/step - loss: 1.3246 - accuracy: 0.1244\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3245573043823242, 0.12436141073703766]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Find The Best Performing Model**"
      ],
      "metadata": {
        "id": "OaUujTlw3zTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(x_train)\n",
        "X_test = np.array(x_test)"
      ],
      "metadata": {
        "id": "dqe-Ka1YzAN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = ak.TextClassifier(max_trials=3)\n",
        "\n",
        "clf.fit(X_train, y_train, validation_split=0.3, epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCwu7Nxty5Pw",
        "outputId": "0338c600-cc7f-4666-9a47-9789be7e6af3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 09m 41s]\n",
            "val_loss: 1.119246006011963\n",
            "\n",
            "Best val_loss So Far: 1.119246006011963\n",
            "Total elapsed time: 00h 10m 44s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Epoch 1/3\n",
            "643/643 [==============================] - 196s 282ms/step - loss: 1.1939 - accuracy: 0.4400\n",
            "Epoch 2/3\n",
            "643/643 [==============================] - 181s 282ms/step - loss: 1.0403 - accuracy: 0.5322\n",
            "Epoch 3/3\n",
            "643/643 [==============================] - 181s 281ms/step - loss: 0.9214 - accuracy: 0.6026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as word_embeddings_layer_call_fn, word_embeddings_layer_call_and_return_conditional_losses, position_embedding_layer_call_fn, position_embedding_layer_call_and_return_conditional_losses, type_embeddings_layer_call_fn while saving (showing 5 of 378). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ./text_classifier/best_model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ./text_classifier/best_model/assets\n",
            "WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7f90e5f8ec10> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7f90e5f8d510> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7f90e960ffd0> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7f90e9637e50> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7f90e94b7610> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7f90e9494f10> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7f90c6a61c90> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7f90c6a53ed0> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7f90e9432590> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7f90c758e990> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7f90c758c490> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7f90e5d38f90> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f90e5cd8510>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = clf.export_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "g5LHyNXg5p1y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "172848c6-3bca-4a13-e41a-7e69afd16d3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " expand_last_dim (ExpandLastDim  (None, 1)           0           ['input_1[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " bert_tokenizer (BertTokenizer)  ((None, None),      0           ['expand_last_dim[0][0]']        \n",
            "                                 (None, None),                                                    \n",
            "                                 (None, None))                                                    \n",
            "                                                                                                  \n",
            " bert_encoder (BertEncoder)     (None, 768)          109482240   ['bert_tokenizer[0][0]',         \n",
            "                                                                  'bert_tokenizer[0][1]',         \n",
            "                                                                  'bert_tokenizer[0][2]']         \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 4)            3076        ['bert_encoder[0][0]']           \n",
            "                                                                                                  \n",
            " classification_head_1 (Softmax  (None, 4)           0           ['dense[0][0]']                  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,485,316\n",
            "Trainable params: 109,485,316\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(base_dir + \"models/clf_best_performing\", save_format = \"tf\")\n",
        "loaded_model = load_model(base_dir + \"models/clf_best_performing\", custom_objects = ak.CUSTOM_OBJECTS)\n",
        "loaded_model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "Goc08MUX571c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "558f3647-c1e0-4d5f-b382-b22420c8d8bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as word_embeddings_layer_call_fn, word_embeddings_layer_call_and_return_conditional_losses, position_embedding_layer_call_fn, position_embedding_layer_call_and_return_conditional_losses, type_embeddings_layer_call_fn while saving (showing 5 of 378). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/University/00012-NLP/MovieClassification/models/clf_best_performing/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/University/00012-NLP/MovieClassification/models/clf_best_performing/assets\n",
            "WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7f9040150590> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7f90401502d0> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7f9040157f10> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7f8e4d7e81d0> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7f9040157b50> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7f9040157e90> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7f9040157c50> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7f8e4db1ac90> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7f9040150550> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7f9040157e10> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7f9040150410> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7f9040157ed0> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "215/215 [==============================] - 23s 99ms/step - loss: 1.1519 - accuracy: 0.4998\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.1518988609313965, 0.4997810423374176]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "13ZeDLxyaRtA",
        "_YlqRoF5kQKW",
        "-9Xc011Hg52h",
        "m5dr_VuO5VGi",
        "tYhASMaCA_4s",
        "XUfudrIy3O9S",
        "OcAi136WKw_A",
        "IutsBQuJ3cja"
      ],
      "name": "MovieClassificationBasedOnMPAUsingPlot.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}